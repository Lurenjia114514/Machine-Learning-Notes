# 模型的选择

## 过拟合

当我们学习的模型为 $Y=\hat{f}(X)$, 定义训练误差为模型对训练集的平均损失, 测试误差为模型对测试集的平均损失, 其中 $N$ 和 $N'$ 为训练集和测试集的样本数量.
$$
\begin{align}
R_{\mathrm{emp}}(\hat{f})&=\frac{1}{N}\sum_{i=1}^NL(y_i,\hat{f}(x_i))\\
e_{\mathrm{test}}&=\frac{1}{N'}\sum_{i=1}^{N'}L(y_i,\hat{f}(x_i))\\
\end{align}
$$

训练误差和测试误差与模型复杂度的关系如下
![](Image\17ea3d0280d1883023c90a7509d1e803.png)

当模型复杂度增大时, 训练误差会减小直至为零, 此时模型对训练集的预测能力增强. 而模型的测试误差则会先减小后增大, 当模型复杂度过大时, 则测试误差会很大, 模型对测试集的预测能力减小, 我们称这种现象为过拟合现象.

为了防止过拟合现象, 我们需要选择复杂度适当的模型, 使得测试误差最小化. 我们通常使用正则化和交叉验证来防止过拟合.

## 正则化

正则化通过在经验风险中添加正则化项, 平衡经验风险和模型复杂度.
$$
\max_{f\in\mathcal{F}} \frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$

正则化项通常为关于模型复杂度的单调递增函数, 即模型越复杂, 正则化项越大.

例如, 线性回归中的岭回归添加参数向量的 $L_2$ 范数
$$
\min_{\omega\in\Omega}\frac{1}{N}\sum_{i=1}^N(f(x_i;\omega)-y_i)^2 +\lambda ||\omega||^2
$$

而 $lasso$ 回归添加了 $L_1$ 范数
$$
\min_{\omega\in\Omega}\frac{1}{N}\sum_{i=1}^N(f(x_i;\omega)-y_i)^2 +\lambda ||\omega||_1
$$

## 交叉验证

$K$ 折交叉验证的原理为

1. 随机将已知数据划分为 $K$ 个互斥且大小相同的子集;
2. 利用 $K-1$ 个子集作为训练集学习模型, 剩下一个作为测试集;
3. 进行 $K$ 次, 选择平均测试误差最小的为最优模型.

## 泛化能力

泛化能力是指模型对未知数据的预测能力, 我们一般通过测试误差进行评价. 接下来我们通过理论推导对模型的泛化能力进行分析.

设学习到的模型为 $\hat{f}$, 则模型对未知数据预测的误差为泛化误差, 即期望风险
$$
R_{\exp}(\hat{f})=E_P[L(Y,\hat{f}(X))]=\int_{\mathcal{X}\times\mathcal{Y}}L(y,\hat{f}(x))P(x,y)\mathrm{d}x\mathrm{d}y
$$

若一个模型比另一个模型的泛化误差小, 则它就更有效. 但通常很难直接计算出泛化误差, 则我们通过比较泛化误差的上界进行比较.

对于二分类问题, 设假设空间为有限集 $\mathcal{F}=\{f_1,\cdots,f_d\}$, 对于任意一个函数 $f\in\mathcal{F}$, 其期望风险为 $R(f)=E[L(Y,f(X))]$, 经验风险为 $\hat{R}(f)=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))$, 则至少有概率 $1-\delta, 0<\delta<1$, 成立不等式
$$
R(f)\le\hat{R}(f)+\varepsilon(d,N,\delta)
$$
其中 $\hat{R}(f)+\varepsilon(d,N,\delta)$ 为泛化误差上界. 若样本量 $n$ 越大, 泛化误差上界越趋于零; 若假设空间量 $d$ 越大, 模型越难学, 泛化误差上界越大; 若训练误差越小, 泛化误差上界越小.
$$
\varepsilon(d,N,\delta)=\sqrt{\frac{1}{2N}}(\log d-\log\delta)
$$