# 机器学习的模型和策略

## 模型

机器学习的模型为条件概率分布或者策略函数, 而模型的假设空间则为所有可能模型的集合.

若假设 $X$ 和 $Y$ 是定义在输入空间和输出空间 $\mathcal{X}$ 和 $\mathcal{Y}$ 的随机变量, 则假设空间 $\mathcal{F}$ 为一个由参数向量 $\boldsymbol{\theta}$ 决定的函数族
$$
\mathcal{F}=\{f|Y=f_{\boldsymbol{\theta}}(X),\boldsymbol{\theta}\in\mathbb{R}^n\}
$$

## 策略

机器学习的目标为从假设空间中选取最优的模型, 即策略.

### 损失函数

损失函数 $L(f(X),Y)$ 是一个关于 $f(X)$ 和 $Y$ 的非负实值函数, 用于衡量模型一次预测的好坏. 损失函数值越小, 模型的性能就越好.

常见的损失函数有:

1. $0-1$ 损失函数
   $$
   L(f(X),Y)=
   \begin{cases}
   1, ~~~Y\ne f(X)\\
   0, ~~~y=f(X)
   \end{cases}
   $$
2. 平方损失函数
   $$
   L(f(X),Y)=(y-f(X))^2
   $$
3. 绝对损失函数
   $$
   L(f(X),Y)=|y-f(X)|
   $$
4. 对数损失函数
   $$
   L(Y,P(Y|X))=-\log P(Y|X)
   $$

损失函数的期望称为风险函数, 衡量平均下的模型预测的好坏.
$$
R_{\exp}(f)=E_P[L(Y,P(Y|X))]=\int_{\mathcal{X}\times\mathcal{Y}}L(Y,P(Y|X))P(x,y)\mathrm{d}x\mathrm{d}y
$$

学习的目标即选择风险函数最小的模型, 但由于联合分布 $P(X,Y)$ 未知, 我们不能直接计算风险函数, 则通过离散化计算风险函数. 若给定训练集为
$$
T=\{(\boldsymbol{x}_1,\boldsymbol{y}_1), \cdots ,(\boldsymbol{x}_N,\boldsymbol{y}_N)\}
$$
则模型 $f(X)$ 关于训练集的平均损失称为经验风险函数
$$
R_{\mathrm{emp}(f)}=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$

期望风险是模型关于联合分布的期望损失, 经验风险是模型关于训练集的平均损失. 根据大数定律, 随着样本量的增加, 检验风险趋于期望风险. 但由于在大多数场景下样本量很小, 我们要对其进行修正, 有经验风险最小化和结构风险最小化.

### 修正

经验风险最小化即求解经验风险最小的模型, 即预测性能最优的模型, 可表示为最优化问题
$$
\max_{f\in\mathcal{F}} \frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$

当模型为条件概率分布, 损失函数为对数损失函数时, 经验风险函数等价于极大似然估计.

当样本量很小时, 模型可能出现过拟合现象, 即在训练集上具有较好的预测性能, 在测试集上的性能则不佳. 结构风险最小化通过添加代表模型复杂度的正则化项, 减少过拟合现象. 结构风险最小化则使得模型在训练集和测试集上均具有优良的性能.
$$
\max_{f\in\mathcal{F}} \frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$
其中如果模型越复杂, 正则化项 $J(f)$ 越大. 而系数 $\lambda$ 用于平衡经验风险和模型复杂度.

当模型为条件概率分布, 损失函数为对数损失函数, 正则化项为模型的先验概率时, 经验风险函数等价于贝叶斯估计中的最大后验概率估计.

## 算法

机器学习的本质为最优化问题, 机器学习的算法即为求解最优化的算法.