# 常见的监督学习

## 分类

当输出变量为离散变量时, 我们称其为分类问题, 且称分类模型为分类器.

设我们关注的类为正类, 其他类为负类, 预测的结果有正确和不正确, 则有

|     | 正类    |负类     |
| --- | --- | --- |
|正确    |  TP   | FP    |
|不正确     | FN    | TN    |

对于二分类问题, 常用的评价指标为准确率和召回率. 
定义准确率为
$$
P=\frac{TP}{TP+FP}
$$
召回率为
$$
R=\frac{TP}{TP+FN}
$$

能用于分类的方法有 $k$ 邻近, 感知机, 朴素贝叶斯, 决策树, 逻辑回归, 支持向量机, Boosting, 贝叶斯网络和神经网络等.

## 标注

标注问题的输入和输出均为序列, 模型通过标注观测序列预测出标记序列.

若给定训练集为
$$
T=\{(x_1,y_1),\cdots,(x_N,y_n)\}
$$
其中 $\boldsymbol{x}$ 为输入序列, $\boldsymbol{y}$ 为输出序列, 学习模型为 $P(\boldsymbol{Y}|\boldsymbol{X})$. 对于 $\boldsymbol{x}_{N+1}$, 我们通过最大化条件概率 $P(\boldsymbol{y}_{N+1}|\boldsymbol{x}_{N+1})$ 得到输出 $\boldsymbol{y}_{N+1}$.

能用于标注的方法有隐马尔可夫和条件随机场等.

## 回归

当输出变量为连续变量时, 我们称其为回归问题, 即选择一个函数曲线去拟合已知数据并很好地预测数据.

回归问题按照输入变量的多少分为一元回归和多元回归; 按照决策函数可分为线性回归和非线性回归.

回归问题常用的损失函数为平方损失函数, 我们可通过最小二乘法求解.